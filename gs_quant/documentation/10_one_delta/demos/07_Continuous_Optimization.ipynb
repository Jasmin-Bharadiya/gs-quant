{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import time\n",
    "from math import copysign\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gs_quant.datetime.relative_date import RelativeDate\n",
    "from gs_quant.markets.position_set import Position, PositionSet, PositionTag\n",
    "from gs_quant.markets.portfolio import Portfolio\n",
    "from gs_quant.markets.portfolio_manager import PortfolioManager\n",
    "from gs_quant.markets.securities import Asset, AssetIdentifier\n",
    "from gs_quant.markets.report import FactorRiskReport, ReturnFormat\n",
    "from gs_quant.models.risk_model import FactorRiskModel\n",
    "from gs_quant.session import GsSession\n",
    "from gs_quant.target.common import PositionSetWeightingStrategy\n",
    "\n",
    "from gs_quant.target.hedge import CorporateActionsTypes\n",
    "from gs_quant.markets.optimizer import OptimizerStrategy, OptimizerUniverse, \\\n",
    "    AssetConstraint, FactorConstraint, SectorConstraint, OptimizerSettings, OptimizerConstraints, \\\n",
    "    OptimizerObjective, OptimizerType\n",
    "\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize your session\n",
    "GsSession.use(client_id='client_id', client_secret='client_secret')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ee60ed7c1a0065e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, let's setup our starting point. We will create a small portfolio of 3 stocks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32dbcc5251b6725f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_date = dt.date(2024, 1, 2)\n",
    "reference_notional = 100_000_000\n",
    "hedge_notional_pct = 0.4\n",
    "universe = ['SPX']\n",
    "rebalance_freq = '3m'\n",
    "risk_model_id = 'AXIOMA_AXUS4S'\n",
    "holdings = [\n",
    "    {\n",
    "        'identifier': 'AAPL UW', \n",
    "        'weight'  : 0.4,\n",
    "        'source': 'Portfolio'\n",
    "    },\n",
    "    {\n",
    "        'identifier': 'MSFT UW',\n",
    "        'weight'  : 0.25,\n",
    "        'source': 'Portfolio'\n",
    "    },\n",
    "    {\n",
    "        'identifier': 'META UW',\n",
    "        'weight'  : 0.25,\n",
    "        'source': 'Portfolio'\n",
    "    }\n",
    "]\n",
    "apply_factor_constraints_on_total = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a60039d9549afdc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you do not have historical identifiers of your holdings, you can use SecurityMaster to resolve today's identifiers to a past point in time. In this example, META is an identifier as of today, not as of 2020.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28dfc1fb4300a20f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gs_quant.api.gs.secmaster import GsSecurityMasterApi\n",
    "\n",
    "historical_identifiers = {}\n",
    " \n",
    "def get_historical_id(identifier, date, listed=True, id_type='bbid'):\n",
    " \n",
    "    data = GsSecurityMasterApi.get_many_securities(**{\"identifier\": [identifier], \"isPrimary\": True})\n",
    "    if not data or 'results' not in data or not data['results']:\n",
    "        raise ValueError(f\"No security found for identifier {identifier}\")\n",
    "    secm_id = data['results'][0]['id']\n",
    "    historical_data = GsSecurityMasterApi.get_identifiers(secmaster_id=secm_id)\n",
    "    for record in historical_data:\n",
    "        start_date = dt.datetime.strptime(record['startDate'], '%Y-%m-%d').date()\n",
    "        end_date = dt.datetime.strptime(record['endDate'], '%Y-%m-%d').date() if record['endDate'] != '9999-99-99' else dt.date.today()\n",
    "        if start_date <= date <= end_date:\n",
    "            if listed and record['type'] == id_type:\n",
    "                return record['value']\n",
    "    return identifier\n",
    " \n",
    "holdings = [\n",
    "    {'identifier': 'META UW'},\n",
    "]\n",
    "start_date = dt.date(2020, 1, 1)\n",
    " \n",
    "for holding in holdings:\n",
    "    try:\n",
    "        historical_identifiers[holding['identifier']] = get_historical_id(holding['identifier'], start_date)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    " \n",
    "historical_identifiers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8122d4ab8610db6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can then use this information to update your holdings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "348122bdff707adb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to replace incorrect identifiers with correct ones\n",
    "def update_identifiers(holdings, historical_identifiers):\n",
    "    for holding in holdings:\n",
    "        incorrect_id = holding['identifier']\n",
    "        if incorrect_id in historical_identifiers:\n",
    "            holding['identifier'] = historical_identifiers[incorrect_id]\n",
    "    return holdings\n",
    " \n",
    "# Update the portfolio positions\n",
    "updated_holdings = update_identifiers(holdings, historical_identifiers)\n",
    " \n",
    "# Print the updated portfolio positions\n",
    "updated_holdings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b4495f9531c9378"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the holdings are finalised, we convert them to a PositionSet object, and resolve them to Marquee Identifiers. We also price our positions to filter out any assets that might be missing prices."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c330e417e4641a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "position_set = PositionSet.from_dicts(\n",
    "    holdings, \n",
    "    date=start_date, \n",
    "    add_tags=True, \n",
    "    reference_notional=reference_notional\n",
    ")\n",
    "position_set.resolve()\n",
    "\n",
    "position_set.to_frame(add_tags=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ad18bac693f0105"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_pset = position_set.clone()\n",
    "combined_pset.price(use_unadjusted_close_price=True,\n",
    "                   weighting_strategy=PositionSetWeightingStrategy.Weight,\n",
    "                   fallbackDate='5d')\n",
    "combined_pset.positions.append(Position(identifier='USD', quantity=hedge_notional_pct*reference_notional*-1, tags=[PositionTag(name='source', value='Optimization')]))\n",
    "combined_pset.resolve()\n",
    "combined_pset.price(use_unadjusted_close_price=True,\n",
    "                    fallbackDate='5d',\n",
    "                    handle_long_short=True)\n",
    "\n",
    "combined_pset.to_frame(add_tags=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b38fc04b8d5671d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "portfolio = Portfolio(name='My New Strategy')\n",
    "portfolio.save()\n",
    "print('Created portfolio with id: {0}'.format(portfolio.id))\n",
    "port_id = portfolio.id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b98c7d30f6f886a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "port_manager = PortfolioManager(port_id)\n",
    "# share the portfolio with your account, as your app is different from yourself \n",
    "port_manager.share(emails=['user.1@yourcompany.com'], admin=True)\n",
    "port_manager.share(emails=['user.2@yourcompany.com'], admin=False)\n",
    "port_manager.update_positions([combined_pset])\n",
    "port_manager.set_tag_name_hierarchy(['source'])\n",
    "\n",
    "risk_report = FactorRiskReport(risk_model_id=risk_model_id)\n",
    "risk_report.set_position_source(port_id)\n",
    "risk_report.save()\n",
    "\n",
    "port_manager.update_portfolio_tree()\n",
    "port_manager.schedule_reports(start_date=position_set.date, \n",
    "                              end_date=RelativeDate(\"5b\", position_set.date).apply_rule())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9362d1c6221d86fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Waiting for risk calculations to complete...')\n",
    "risk_report = port_manager.get_factor_risk_report(risk_model_id=risk_model_id, tags={'source': 'Portfolio'})\n",
    "risk_report.get_most_recent_job().wait_for_completion()\n",
    "\n",
    "factor_exposure_data = risk_report.get_factor_exposure(start_date=position_set.date, end_date=position_set.date)\n",
    "factor_exposure_map = factor_exposure_data.to_dict(orient='records')[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b6f5768cc18b35b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_factor_constraints(factor_constraints, port_factor_exposure_map):\n",
    "    \"\"\"Given factor constraints defined on the total portfolio and factor exposures of the core portfolio, \n",
    "    return constraints to be applied on the hedge\"\"\"\n",
    "    new_constraints = []\n",
    "    for fc in factor_constraints:\n",
    "        old = fc.max_exposure\n",
    "        new = port_factor_exposure_map.get(fc.factor.name, 0) - fc.max_exposure\n",
    "        print('Changing factor constraint for ', fc.factor.name, 'from ', old, 'to ', new)\n",
    "        new_constraints.append(\n",
    "            FactorConstraint(\n",
    "                fc.factor,\n",
    "                port_factor_exposure_map.get(fc.factor.name, 0) - fc.max_exposure\n",
    "            )\n",
    "        )\n",
    "    return new_constraints"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9286ce2c6ece38cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that you have a position set, you can get a hedge according to your liking. We have put in some sample settings below. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6800b724c0bfa2ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hedge_universe = OptimizerUniverse(\n",
    "    assets=[Asset.get(a, AssetIdentifier.BLOOMBERG_ID) for a in universe],\n",
    "    explode_composites=True,\n",
    "    exclude_corporate_actions_types=[CorporateActionsTypes.Mergers]\n",
    ")\n",
    "\n",
    "risk_model = FactorRiskModel.get(risk_model_id)\n",
    "\n",
    "asset_constraints = [\n",
    "    AssetConstraint(Asset.get('MSFT UW', AssetIdentifier.BLOOMBERG_ID), 0, 5),\n",
    "    AssetConstraint(Asset.get('AAPL UW', AssetIdentifier.BLOOMBERG_ID), 0, 5)\n",
    "]\n",
    "\n",
    "# here, we have specified the constraints on factor exposure of the Total Optimized portfolio\n",
    "factor_constraints = [\n",
    "    FactorConstraint(risk_model.get_factor('Size'), 0),\n",
    "    FactorConstraint(risk_model.get_factor('Market Sensitivity'), 0)\n",
    "]\n",
    "\n",
    "if apply_factor_constraints_on_total:\n",
    "    hedge_factor_constraints = prepare_factor_constraints(factor_constraints, factor_exposure_map)\n",
    "else:\n",
    "    hedge_factor_constraints = factor_constraints\n",
    " \n",
    "sector_constraints = [\n",
    "    SectorConstraint('Energy', 0, 30),\n",
    "    SectorConstraint('Health Care', 0, 30)\n",
    "]\n",
    "settings = OptimizerSettings(notional=hedge_notional_pct * position_set.reference_notional, # 40% of your original portfolio \n",
    "                             allow_long_short=False)\n",
    "constraints = OptimizerConstraints(\n",
    "    asset_constraints=asset_constraints,\n",
    "    factor_constraints=hedge_factor_constraints,\n",
    "    sector_constraints=sector_constraints,\n",
    ")\n",
    "\n",
    "strategy = OptimizerStrategy(\n",
    "    initial_position_set=position_set,\n",
    "    constraints=constraints,\n",
    "    settings=settings,\n",
    "    universe=hedge_universe,\n",
    "    risk_model=risk_model,\n",
    "    objective=OptimizerObjective.MINIMIZE_FACTOR_RISK\n",
    ")\n",
    "\n",
    "strategy.run(optimizer_type=OptimizerType.AXIOMA_PORTFOLIO_OPTIMIZER)\n",
    "\n",
    "optimization = strategy.get_optimization(by_weight=True) # Returns just the optimization results as a PositionSet object\n",
    "optimization.to_frame()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "829ffee757033b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Optimizer uses adjusted prices, while the portfolio analytics use unadjusted prices to offer users more fine-grained control on historical positions. We need to convert output from hedger to unadjusted prices to be able to use it in the portfolio analytics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13b77816be333b3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "position_set.price(use_unadjusted_close_price=True,\n",
    "                   weighting_strategy=PositionSetWeightingStrategy.Weight,\n",
    "                   fallbackDate='5d')\n",
    "\n",
    "optimization.price(use_unadjusted_close_price=True,\n",
    "                   weighting_strategy=PositionSetWeightingStrategy.Weight,\n",
    "                   fallbackDate='5d')\n",
    "\n",
    "for p in optimization.positions:\n",
    "    p.quantity *= -1\n",
    "    p.add_tag('source', 'Optimization')\n",
    "\n",
    "combined_pset = PositionSet(\n",
    "    date=position_set.date,\n",
    "    # take only quantity of the newly priced positions\n",
    "    positions=[Position(identifier=p.identifier, asset_id=p.asset_id, quantity=p.quantity, tags=p.tags) for p in position_set.positions+optimization.positions]\n",
    ")\n",
    "combined_pset.to_frame()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffeb9251c171a8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "port_manager.update_positions([combined_pset])\n",
    "port_manager.schedule_reports(start_date=combined_pset.date, \n",
    "                              end_date=RelativeDate(rebalance_freq, combined_pset.date).apply_rule())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cff94b8b386e7d99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "With our initial setup done and settings configured, we are now ready to launch a flow that will continuously optimize our portfolio at our desired frequency.\n",
    "\n",
    "We will take th positions from the previous rebalance, utilize performance analytics to get the latest positions, and then optimize the portfolio again. We will then update the portfolio with the new positions and schedule reports for the next rebalance date.\n",
    "\n",
    "This operation of moving your portfolio forward using performance analytics relies solely on availability of the underlying assets. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81de648080f25477"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "port_manager = PortfolioManager(port_id)\n",
    "start = position_set.date\n",
    "max_end = RelativeDate(\"-1b\", dt.date.today()).apply_rule(exchanges=['NYSE'])\n",
    "start_time = time.time()\n",
    "rebal = RelativeDate(rebalance_freq, start).apply_rule(exchanges=['NYSE'])\n",
    "\n",
    "while rebal < max_end:\n",
    "    print(f'Moving to rebalance date {rebal}')\n",
    "    port_perf_report   = port_manager.get_performance_report({'source': 'Portfolio'})\n",
    "    perf_report_job = port_perf_report.get_most_recent_job()\n",
    "    print(f'Waiting for performance calculations till date {perf_report_job.end_date} to complete (job id {perf_report_job.job_id})')\n",
    "    perf_report_job.wait_for_completion()\n",
    "    \n",
    "    latest_port_pos    = port_perf_report.get_portfolio_constituents(\n",
    "        start_date=rebal, \n",
    "        end_date=rebal, \n",
    "        fields=['quantity', 'grossWeight'], \n",
    "        prefer_rebalance_positions=True,\n",
    "        return_format=ReturnFormat.JSON\n",
    "    )\n",
    "    latest_port_exp    = port_perf_report.get_gross_exposure(start_date=rebal, end_date=rebal)['grossExposure'][0]\n",
    "    latest_position_set = PositionSet(\n",
    "                date=rebal,\n",
    "                reference_notional=latest_port_exp,\n",
    "                positions=[Position(\n",
    "                    asset_id=p['assetId'],\n",
    "                    identifier=p['assetId'],\n",
    "                    # We recommend using gross weight to find your reference weight, like below\n",
    "                    weight=copysign(p.get('grossWeight', 0), p.get('quantity', 0)),\n",
    "                    tags=[{'source': 'Portfolio'}]\n",
    "                ) for p in latest_port_pos]\n",
    "            )\n",
    "    print('Latest Portfolio Position set:')\n",
    "    print(latest_position_set.to_frame(add_tags=True))\n",
    "    settings = OptimizerSettings(notional=hedge_notional_pct * latest_position_set.reference_notional, # 30% of your original portfolio \n",
    "                                 allow_long_short=False)\n",
    "    \n",
    "    if factor_constraints and apply_factor_constraints_on_total:\n",
    "        port_risk_report   = port_manager.get_factor_risk_report(risk_model_id=risk_model_id, tags={'source': 'Portfolio'})\n",
    "        risk_report_job = port_risk_report.get_most_recent_job()\n",
    "        print(f'Waiting for risk calculations till date {risk_report_job.end_date} to complete (job id {risk_report_job.job_id})')\n",
    "        risk_report_job.wait_for_completion()\n",
    "        \n",
    "        factor_exposure_data = risk_report.get_factor_exposure(start_date=latest_position_set.date, end_date=latest_position_set.date)\n",
    "        factor_exposure_map = factor_exposure_data.to_dict(orient='records')[0]\n",
    "        hedge_factor_constraints = prepare_factor_constraints(factor_constraints, factor_exposure_map)\n",
    "    else:\n",
    "        hedge_factor_constraints = factor_constraints\n",
    "    \n",
    "    constraints = OptimizerConstraints(\n",
    "        asset_constraints=asset_constraints,\n",
    "        factor_constraints=hedge_factor_constraints,\n",
    "        sector_constraints=sector_constraints,\n",
    "    )\n",
    "    strategy = OptimizerStrategy(\n",
    "        initial_position_set=latest_position_set,\n",
    "        constraints=constraints,\n",
    "        settings=settings,\n",
    "        universe=hedge_universe,\n",
    "        risk_model=risk_model,\n",
    "        objective=OptimizerObjective.MINIMIZE_FACTOR_RISK\n",
    "    )\n",
    "    print('Optimizing...')\n",
    "    strategy.run(optimizer_type=OptimizerType.AXIOMA_PORTFOLIO_OPTIMIZER)\n",
    "    print('Optimization complete')\n",
    "    print('Optimized Position Set quantities:')\n",
    "    print(strategy.get_optimized_position_set().to_frame())\n",
    "    optimization = strategy.get_optimization(by_weight=True)\n",
    "    print('Hedge position set:')\n",
    "    print(optimization.to_frame(add_tags=True))\n",
    "    optimization.price(\n",
    "        use_unadjusted_close_price=True,\n",
    "        weighting_strategy=PositionSetWeightingStrategy.Weight,\n",
    "        fallbackDate='5d'\n",
    "    )\n",
    "    for p in optimization.positions:\n",
    "        p.quantity *= -1\n",
    "        p.add_tag('source', 'Optimization')\n",
    "    latest_position_set.price(\n",
    "        use_unadjusted_close_price=True,\n",
    "        weighting_strategy=PositionSetWeightingStrategy.Weight,\n",
    "        fallbackDate='5d'\n",
    "    )\n",
    "    combined_pset = PositionSet(\n",
    "        date=optimization.date,\n",
    "        positions=[Position(identifier=p.identifier, asset_id=p.asset_id, quantity=p.quantity, tags=p.tags) for p in latest_position_set.positions+optimization.positions]\n",
    "    )\n",
    "    print('Combined position set:')\n",
    "    print(combined_pset.to_frame(add_tags=True))\n",
    "    port_manager.update_positions([combined_pset])\n",
    "    start = rebal\n",
    "    rebal = min(max_end, RelativeDate(rebalance_freq, start).apply_rule())\n",
    "    print(f'Scheduling reports to calculate performance till {rebal}...')\n",
    "    port_manager.schedule_reports(start_date=start,\n",
    "                                  end_date=rebal)\n",
    "    time.sleep(2)\n",
    "\n",
    "print(f'Done! Processing completed in {time.time() - start_time} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a57977f27fa4717"
  },
  {
   "cell_type": "markdown",
   "source": [
    "And that's it! You have successfully completed a basic run of our Quant Backtesting Workflow. \n",
    "\n",
    "For questions, please reach out to [Marquee Sales](mailto:gs-marquee-sales@gs.com)!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23208a6f7f529d31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
